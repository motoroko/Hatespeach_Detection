{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/motoroko/Hatespeach_Detection/blob/main/Hatespeach_Detection_using_Hybrid_NB_SVM_MLP_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHyP9yLxWLFf",
        "outputId": "3e648a43-03d1-496e-8ee6-ce455977f213"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.text import Text\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "!pip install Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bbiR6RN9IpcQ",
        "outputId": "6ecd169f-08b3-4682-b9b0-06fb53312d60"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0e77f163-be18-43cd-950c-5618af90797c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @Ardiesuhardi1: @CintaNirmala2 @IrmansyahAd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @Ardiesuhardi1: @CintaNirmala2 @Bianglala_0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @HaneutM: Semoga..\\n#21AprilJokowiTumbang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @dancersejati1: JAKSA AGUNG MANTAP!\\nKorupt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @Ardiesuhardi1: @banditBirokrat @Sangkurian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @DimasAnugrahe: Terimakasih pada semua piha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @CantikaAndiP: Terimakasih pada semua pihak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4430</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @CantikaAndiP: Terimakasih pada semua pihak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4431</th>\n",
              "      <td>Non_HS</td>\n",
              "      <td>RT @JoniSaputra00: Aamiin!! semoga lancar samp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4432</th>\n",
              "      <td>HS</td>\n",
              "      <td>RT @EunikeLavenia: wow … gara - gara One Way, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4433 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e77f163-be18-43cd-950c-5618af90797c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e77f163-be18-43cd-950c-5618af90797c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e77f163-be18-43cd-950c-5618af90797c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Label                                              Tweet\n",
              "0         HS  RT @Ardiesuhardi1: @CintaNirmala2 @IrmansyahAd...\n",
              "1         HS  RT @Ardiesuhardi1: @CintaNirmala2 @Bianglala_0...\n",
              "2         HS       RT @HaneutM: Semoga..\\n#21AprilJokowiTumbang\n",
              "3         HS  RT @dancersejati1: JAKSA AGUNG MANTAP!\\nKorupt...\n",
              "4         HS  RT @Ardiesuhardi1: @banditBirokrat @Sangkurian...\n",
              "...      ...                                                ...\n",
              "4428      HS  RT @DimasAnugrahe: Terimakasih pada semua piha...\n",
              "4429      HS  RT @CantikaAndiP: Terimakasih pada semua pihak...\n",
              "4430      HS  RT @CantikaAndiP: Terimakasih pada semua pihak...\n",
              "4431  Non_HS  RT @JoniSaputra00: Aamiin!! semoga lancar samp...\n",
              "4432      HS  RT @EunikeLavenia: wow … gara - gara One Way, ...\n",
              "\n",
              "[4433 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('Data_Hatespeach.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRnlaU1MWOjh"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower() #lowercase atau case folding\n",
        "  text = re.sub('@[^\\s]+', '', text) #remove username\n",
        "  text = re.sub('\\[.*?\\]', '', text) # remove square brackets\n",
        "  text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', text) # remove URLs\n",
        "  text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n",
        "  text = re.sub('\\w*\\d\\w*', '', text)\n",
        "  text = re.sub('[‘’“”…]', '', text)\n",
        "  text = re.sub('\\n', '', text)\n",
        "  return text\n",
        "\n",
        "clean1 = lambda x: clean_text(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4L2CnXiWTn5"
      },
      "outputs": [],
      "source": [
        "df['Tweet'] = pd.DataFrame(df['Tweet'].apply(clean1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5p17jFIWfyo",
        "outputId": "72c8fd7e-2fc2-4e8f-d81e-e6581e0ce89d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    1]\n",
            " [3291 1142]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Class_encoder = LabelEncoder().fit_transform(df.Label)\n",
        "unique, counts = np.unique(Class_encoder, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ieUqYBtbWiR4",
        "outputId": "9c8d5de4-3d75-404f-c993-c1d74172a32a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6cfccf82-3325-46e8-98e3-142c2e33fbaf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2832</th>\n",
              "      <th>2833</th>\n",
              "      <th>2834</th>\n",
              "      <th>2835</th>\n",
              "      <th>2836</th>\n",
              "      <th>2837</th>\n",
              "      <th>2838</th>\n",
              "      <th>2839</th>\n",
              "      <th>2840</th>\n",
              "      <th>2841</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4430</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4431</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4432</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4433 rows × 2842 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cfccf82-3325-46e8-98e3-142c2e33fbaf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cfccf82-3325-46e8-98e3-142c2e33fbaf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cfccf82-3325-46e8-98e3-142c2e33fbaf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0     1     2     3     4     5     6     7     8     9     ...  2832  \\\n",
              "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "4428     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "4429     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "4430     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "4431     0     0     0     1     0     0     0     0     0     0  ...     0   \n",
              "4432     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "\n",
              "      2833  2834  2835  2836  2837  2838  2839  2840  2841  \n",
              "0        0     0     0     0     0     0     0     0     0  \n",
              "1        0     0     0     0     0     0     0     0     0  \n",
              "2        0     0     0     0     0     0     0     0     0  \n",
              "3        0     0     0     0     0     0     0     0     0  \n",
              "4        0     0     0     0     0     0     0     0     0  \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "4428     0     0     0     0     0     0     0     0     0  \n",
              "4429     0     0     0     0     0     0     0     0     0  \n",
              "4430     0     0     0     0     0     0     0     0     0  \n",
              "4431     0     0     0     0     0     0     0     0     0  \n",
              "4432     0     0     0     0     0     0     0     0     0  \n",
              "\n",
              "[4433 rows x 2842 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "stop_words = stopwords.words('indonesian')\n",
        "CountVectorizer = CountVectorizer(min_df=5, max_df=0.7, ngram_range = (1,5), stop_words=stop_words)\n",
        "df_vector = CountVectorizer.fit_transform(df.Tweet).toarray()\n",
        "df_vector = pd.DataFrame(df_vector)\n",
        "df_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd6MJtpNuT9y"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8TCA2VDswoP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_TkECQUTKF1",
        "outputId": "d09ad379-0c3f-4e8f-dd10-f593f90b75e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "kf.get_n_splits(df_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqBA04vxkvGy"
      },
      "source": [
        "## NB Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThVXVH2J6cWw"
      },
      "source": [
        "### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRBnyCxW4_lA",
        "outputId": "4bab51c0-672c-48d9-81d6-adf519c712f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n",
            "[CV 1/2] END .........................alpha=0.1;, score=0.645 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=0.1;, score=0.683 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=0.2;, score=0.636 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=0.2;, score=0.683 total time=   0.2s\n",
            "[CV 1/2] END .........alpha=0.30000000000000004;, score=0.634 total time=   0.2s\n",
            "[CV 2/2] END .........alpha=0.30000000000000004;, score=0.670 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=0.4;, score=0.628 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=0.4;, score=0.664 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=0.5;, score=0.628 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=0.5;, score=0.664 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=0.6;, score=0.624 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=0.6;, score=0.664 total time=   0.2s\n",
            "[CV 1/2] END ..........alpha=0.7000000000000001;, score=0.621 total time=   0.2s\n",
            "[CV 2/2] END ..........alpha=0.7000000000000001;, score=0.663 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=0.8;, score=0.620 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=0.8;, score=0.662 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=0.9;, score=0.609 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=0.9;, score=0.660 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=1.0;, score=0.604 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=1.0;, score=0.660 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=1.1;, score=0.601 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=1.1;, score=0.657 total time=   0.2s\n",
            "[CV 1/2] END ..........alpha=1.2000000000000002;, score=0.600 total time=   0.2s\n",
            "[CV 2/2] END ..........alpha=1.2000000000000002;, score=0.657 total time=   0.2s\n",
            "[CV 1/2] END ..........alpha=1.3000000000000003;, score=0.601 total time=   0.2s\n",
            "[CV 2/2] END ..........alpha=1.3000000000000003;, score=0.655 total time=   0.2s\n",
            "[CV 1/2] END ..........alpha=1.4000000000000001;, score=0.601 total time=   0.2s\n",
            "[CV 2/2] END ..........alpha=1.4000000000000001;, score=0.654 total time=   0.2s\n",
            "[CV 1/2] END ..........alpha=1.5000000000000002;, score=0.600 total time=   0.2s\n",
            "[CV 2/2] END ..........alpha=1.5000000000000002;, score=0.655 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=1.6;, score=0.600 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=1.6;, score=0.655 total time=   0.2s\n",
            "[CV 1/2] END ..........alpha=1.7000000000000002;, score=0.600 total time=   0.2s\n",
            "[CV 2/2] END ..........alpha=1.7000000000000002;, score=0.655 total time=   0.2s\n",
            "[CV 1/2] END ..........alpha=1.8000000000000003;, score=0.600 total time=   0.2s\n",
            "[CV 2/2] END ..........alpha=1.8000000000000003;, score=0.654 total time=   0.2s\n",
            "[CV 1/2] END ..........alpha=1.9000000000000001;, score=0.595 total time=   0.2s\n",
            "[CV 2/2] END ..........alpha=1.9000000000000001;, score=0.653 total time=   0.2s\n",
            "[CV 1/2] END .........................alpha=2.0;, score=0.596 total time=   0.2s\n",
            "[CV 2/2] END .........................alpha=2.0;, score=0.653 total time=   0.2s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=MultinomialNB(),\n",
              "             param_grid={'alpha': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6,\n",
              "                                   0.7000000000000001, 0.8, 0.9, 1.0, 1.1,\n",
              "                                   1.2000000000000002, 1.3000000000000003,\n",
              "                                   1.4000000000000001, 1.5000000000000002, 1.6,\n",
              "                                   1.7000000000000002, 1.8000000000000003,\n",
              "                                   1.9000000000000001, 2.0]},\n",
              "             verbose=3)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters = {\n",
        "    'alpha':list(np.arange(0.1,2.1,0.1))\n",
        "}\n",
        "MNB = MultinomialNB()\n",
        "clf = GridSearchCV(MNB, parameters, verbose=3, cv=2)\n",
        "clf.fit(df_vector, Class_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu39e57T5uET",
        "outputId": "2f31cd91-6d45-400b-9af9-eaaf68cf3ceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parameter terbaik :  {'alpha': 0.1}\n",
            "Akurasi parameter :  0.663888759975835\n"
          ]
        }
      ],
      "source": [
        "print('parameter terbaik : ',clf.best_params_)\n",
        "print('Akurasi parameter : ',clf.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLR1EQ-l6fyQ"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92UMJJCpkyPc",
        "outputId": "2b36f8a8-0761-4f99-ad7f-36eab21c102f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold ke =  1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85       656\n",
            "           1       0.58      0.84      0.69       231\n",
            "\n",
            "    accuracy                           0.80       887\n",
            "   macro avg       0.76      0.81      0.77       887\n",
            "weighted avg       0.84      0.80      0.81       887\n",
            "\n",
            "Accuracy : 79.932 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86       642\n",
            "           1       0.62      0.85      0.72       245\n",
            "\n",
            "    accuracy                           0.81       887\n",
            "   macro avg       0.78      0.83      0.79       887\n",
            "weighted avg       0.85      0.81      0.82       887\n",
            "\n",
            "Accuracy : 81.398 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.80      0.87       666\n",
            "           1       0.59      0.87      0.70       221\n",
            "\n",
            "    accuracy                           0.81       887\n",
            "   macro avg       0.77      0.83      0.78       887\n",
            "weighted avg       0.86      0.81      0.82       887\n",
            "\n",
            "Accuracy : 81.398 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.82      0.87       660\n",
            "           1       0.61      0.84      0.71       226\n",
            "\n",
            "    accuracy                           0.82       886\n",
            "   macro avg       0.77      0.83      0.79       886\n",
            "weighted avg       0.85      0.82      0.83       886\n",
            "\n",
            "Accuracy : 82.280 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.78      0.85       667\n",
            "           1       0.56      0.84      0.68       219\n",
            "\n",
            "    accuracy                           0.80       886\n",
            "   macro avg       0.75      0.81      0.76       886\n",
            "weighted avg       0.85      0.80      0.81       886\n",
            "\n",
            "Accuracy : 79.910 %\n",
            "--------------------------------------------------\n",
            "Rata-rata akurasi metode : 80.984 %\n"
          ]
        }
      ],
      "source": [
        "n_fold = 1\n",
        "akurasi = []\n",
        "for train_index, test_index in kf.split(df_vector):\n",
        "  print('Fold ke = ',n_fold)\n",
        "  x_train, x_test = df_vector.iloc[train_index], df_vector.iloc[test_index]\n",
        "  y_train, y_test = Class_encoder[train_index], Class_encoder[test_index]\n",
        "\n",
        "  NB_model = MultinomialNB(**clf.best_params_)\n",
        "  NB_model.fit(x_train,y_train)\n",
        "  NB_pred = NB_model.predict(x_test)\n",
        "\n",
        "  print(classification_report(y_test,NB_pred))\n",
        "\n",
        "  unique, counts = np.unique((y_test == NB_pred.reshape(NB_pred.shape[0],)), return_counts=True)\n",
        "  acc = (counts[1]/np.sum(counts)) * 100\n",
        "  akurasi.append(acc)\n",
        "  n_fold += 1\n",
        "  print(f'Accuracy : {acc:.3f} %'.format(acc))\n",
        "  print('-'*50)\n",
        "\n",
        "print(f'Rata-rata akurasi metode : {np.mean(akurasi):.3f} %'.format(np.mean(akurasi)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHThLWuYuWQ_"
      },
      "source": [
        "## SVM Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snPvmD0k85RP"
      },
      "source": [
        "### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1cZpASq6vcV",
        "outputId": "5411467e-c336-4e87-e5b6-831198f901fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 200 candidates, totalling 400 fits\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=scale, kernel=linear;, score=0.548 total time=   9.1s\n",
            "[CV 2/2] END C=0.01, degree=1, gamma=scale, kernel=linear;, score=0.744 total time=  14.3s\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=scale, kernel=poly;, score=0.742 total time=  14.4s\n",
            "[CV 2/2] END C=0.01, degree=1, gamma=scale, kernel=poly;, score=0.742 total time=  22.3s\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=scale, kernel=rbf;, score=0.584 total time=  18.0s\n",
            "[CV 2/2] END C=0.01, degree=1, gamma=scale, kernel=rbf;, score=0.742 total time=  23.5s\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=scale, kernel=sigmoid;, score=0.742 total time=  15.5s\n",
            "[CV 2/2] END C=0.01, degree=1, gamma=scale, kernel=sigmoid;, score=0.742 total time=  13.2s\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=auto, kernel=linear;, score=0.548 total time=   9.5s\n",
            "[CV 2/2] END C=0.01, degree=1, gamma=auto, kernel=linear;, score=0.744 total time=  16.4s\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=auto, kernel=poly;, score=0.742 total time=  18.1s\n",
            "[CV 2/2] END C=0.01, degree=1, gamma=auto, kernel=poly;, score=0.742 total time=  15.3s\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=auto, kernel=rbf;, score=0.742 total time=  17.0s\n",
            "[CV 2/2] END C=0.01, degree=1, gamma=auto, kernel=rbf;, score=0.742 total time=  14.5s\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.4s\n",
            "[CV 2/2] END C=0.01, degree=1, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.2s\n",
            "[CV 1/2] END C=0.01, degree=2, gamma=scale, kernel=linear;, score=0.548 total time=   8.3s\n",
            "[CV 2/2] END C=0.01, degree=2, gamma=scale, kernel=linear;, score=0.744 total time=  12.4s\n",
            "[CV 1/2] END C=0.01, degree=2, gamma=scale, kernel=poly;, score=0.742 total time=  11.2s\n",
            "[CV 2/2] END C=0.01, degree=2, gamma=scale, kernel=poly;, score=0.742 total time=  13.2s\n",
            "[CV 1/2] END C=0.01, degree=2, gamma=scale, kernel=rbf;, score=0.584 total time=  14.5s\n",
            "[CV 2/2] END C=0.01, degree=2, gamma=scale, kernel=rbf;, score=0.742 total time=  15.4s\n",
            "[CV 1/2] END C=0.01, degree=2, gamma=scale, kernel=sigmoid;, score=0.742 total time=  11.7s\n",
            "[CV 2/2] END C=0.01, degree=2, gamma=scale, kernel=sigmoid;, score=0.742 total time=  11.7s\n",
            "[CV 1/2] END C=0.01, degree=2, gamma=auto, kernel=linear;, score=0.548 total time=   7.1s\n",
            "[CV 2/2] END C=0.01, degree=2, gamma=auto, kernel=linear;, score=0.744 total time=  11.7s\n",
            "[CV 1/2] END C=0.01, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  10.8s\n",
            "[CV 2/2] END C=0.01, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  11.0s\n",
            "[CV 1/2] END C=0.01, degree=2, gamma=auto, kernel=rbf;, score=0.742 total time=  14.0s\n",
            "[CV 2/2] END C=0.01, degree=2, gamma=auto, kernel=rbf;, score=0.742 total time=  14.0s\n",
            "[CV 1/2] END C=0.01, degree=2, gamma=auto, kernel=sigmoid;, score=0.742 total time=  10.7s\n",
            "[CV 2/2] END C=0.01, degree=2, gamma=auto, kernel=sigmoid;, score=0.742 total time=  10.7s\n",
            "[CV 1/2] END C=0.01, degree=3, gamma=scale, kernel=linear;, score=0.548 total time=  10.6s\n",
            "[CV 2/2] END C=0.01, degree=3, gamma=scale, kernel=linear;, score=0.744 total time=  16.2s\n",
            "[CV 1/2] END C=0.01, degree=3, gamma=scale, kernel=poly;, score=0.742 total time=  12.8s\n",
            "[CV 2/2] END C=0.01, degree=3, gamma=scale, kernel=poly;, score=0.742 total time=  15.8s\n",
            "[CV 1/2] END C=0.01, degree=3, gamma=scale, kernel=rbf;, score=0.584 total time=  18.8s\n",
            "[CV 2/2] END C=0.01, degree=3, gamma=scale, kernel=rbf;, score=0.742 total time=  21.2s\n",
            "[CV 1/2] END C=0.01, degree=3, gamma=scale, kernel=sigmoid;, score=0.742 total time=  13.8s\n",
            "[CV 2/2] END C=0.01, degree=3, gamma=scale, kernel=sigmoid;, score=0.742 total time=  15.3s\n",
            "[CV 1/2] END C=0.01, degree=3, gamma=auto, kernel=linear;, score=0.548 total time=  10.0s\n",
            "[CV 2/2] END C=0.01, degree=3, gamma=auto, kernel=linear;, score=0.744 total time=  15.9s\n",
            "[CV 1/2] END C=0.01, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  12.7s\n",
            "[CV 2/2] END C=0.01, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  12.7s\n",
            "[CV 1/2] END C=0.01, degree=3, gamma=auto, kernel=rbf;, score=0.742 total time=  21.4s\n",
            "[CV 2/2] END C=0.01, degree=3, gamma=auto, kernel=rbf;, score=0.742 total time=  20.9s\n",
            "[CV 1/2] END C=0.01, degree=3, gamma=auto, kernel=sigmoid;, score=0.742 total time=  14.7s\n",
            "[CV 2/2] END C=0.01, degree=3, gamma=auto, kernel=sigmoid;, score=0.742 total time=  14.6s\n",
            "[CV 1/2] END C=0.01, degree=4, gamma=scale, kernel=linear;, score=0.548 total time=  10.5s\n",
            "[CV 2/2] END C=0.01, degree=4, gamma=scale, kernel=linear;, score=0.744 total time=  16.8s\n",
            "[CV 1/2] END C=0.01, degree=4, gamma=scale, kernel=poly;, score=0.742 total time=  18.8s\n",
            "[CV 2/2] END C=0.01, degree=4, gamma=scale, kernel=poly;, score=0.742 total time=  18.4s\n",
            "[CV 1/2] END C=0.01, degree=4, gamma=scale, kernel=rbf;, score=0.584 total time=  18.8s\n",
            "[CV 2/2] END C=0.01, degree=4, gamma=scale, kernel=rbf;, score=0.742 total time=  20.2s\n",
            "[CV 1/2] END C=0.01, degree=4, gamma=scale, kernel=sigmoid;, score=0.742 total time=  13.8s\n",
            "[CV 2/2] END C=0.01, degree=4, gamma=scale, kernel=sigmoid;, score=0.742 total time=  15.6s\n",
            "[CV 1/2] END C=0.01, degree=4, gamma=auto, kernel=linear;, score=0.548 total time=   9.5s\n",
            "[CV 2/2] END C=0.01, degree=4, gamma=auto, kernel=linear;, score=0.744 total time=  12.8s\n",
            "[CV 1/2] END C=0.01, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  12.2s\n",
            "[CV 2/2] END C=0.01, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  16.9s\n",
            "[CV 1/2] END C=0.01, degree=4, gamma=auto, kernel=rbf;, score=0.742 total time=  21.2s\n",
            "[CV 2/2] END C=0.01, degree=4, gamma=auto, kernel=rbf;, score=0.742 total time=  17.5s\n",
            "[CV 1/2] END C=0.01, degree=4, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.8s\n",
            "[CV 2/2] END C=0.01, degree=4, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.2s\n",
            "[CV 1/2] END C=0.01, degree=5, gamma=scale, kernel=linear;, score=0.548 total time=   7.5s\n",
            "[CV 2/2] END C=0.01, degree=5, gamma=scale, kernel=linear;, score=0.744 total time=  14.7s\n",
            "[CV 1/2] END C=0.01, degree=5, gamma=scale, kernel=poly;, score=0.742 total time=  13.9s\n",
            "[CV 2/2] END C=0.01, degree=5, gamma=scale, kernel=poly;, score=0.743 total time=  18.1s\n",
            "[CV 1/2] END C=0.01, degree=5, gamma=scale, kernel=rbf;, score=0.584 total time=  17.9s\n",
            "[CV 2/2] END C=0.01, degree=5, gamma=scale, kernel=rbf;, score=0.742 total time=  21.0s\n",
            "[CV 1/2] END C=0.01, degree=5, gamma=scale, kernel=sigmoid;, score=0.742 total time=  14.2s\n",
            "[CV 2/2] END C=0.01, degree=5, gamma=scale, kernel=sigmoid;, score=0.742 total time=  15.7s\n",
            "[CV 1/2] END C=0.01, degree=5, gamma=auto, kernel=linear;, score=0.548 total time=  14.2s\n",
            "[CV 2/2] END C=0.01, degree=5, gamma=auto, kernel=linear;, score=0.744 total time=  12.5s\n",
            "[CV 1/2] END C=0.01, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  14.6s\n",
            "[CV 2/2] END C=0.01, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  16.1s\n",
            "[CV 1/2] END C=0.01, degree=5, gamma=auto, kernel=rbf;, score=0.742 total time=  14.6s\n",
            "[CV 2/2] END C=0.01, degree=5, gamma=auto, kernel=rbf;, score=0.742 total time=  14.2s\n",
            "[CV 1/2] END C=0.01, degree=5, gamma=auto, kernel=sigmoid;, score=0.742 total time=  10.9s\n",
            "[CV 2/2] END C=0.01, degree=5, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.6s\n",
            "[CV 1/2] END C=0.1, degree=1, gamma=scale, kernel=linear;, score=0.563 total time=   2.4s\n",
            "[CV 2/2] END C=0.1, degree=1, gamma=scale, kernel=linear;, score=0.769 total time=  12.1s\n",
            "[CV 1/2] END C=0.1, degree=1, gamma=scale, kernel=poly;, score=0.558 total time=  11.7s\n",
            "[CV 2/2] END C=0.1, degree=1, gamma=scale, kernel=poly;, score=0.743 total time=  12.7s\n",
            "[CV 1/2] END C=0.1, degree=1, gamma=scale, kernel=rbf;, score=0.576 total time=   8.2s\n",
            "[CV 2/2] END C=0.1, degree=1, gamma=scale, kernel=rbf;, score=0.742 total time=  15.9s\n",
            "[CV 1/2] END C=0.1, degree=1, gamma=scale, kernel=sigmoid;, score=0.756 total time=  11.5s\n",
            "[CV 2/2] END C=0.1, degree=1, gamma=scale, kernel=sigmoid;, score=0.742 total time=  12.2s\n",
            "[CV 1/2] END C=0.1, degree=1, gamma=auto, kernel=linear;, score=0.563 total time=   2.3s\n",
            "[CV 2/2] END C=0.1, degree=1, gamma=auto, kernel=linear;, score=0.769 total time=  11.6s\n",
            "[CV 1/2] END C=0.1, degree=1, gamma=auto, kernel=poly;, score=0.742 total time=  11.4s\n",
            "[CV 2/2] END C=0.1, degree=1, gamma=auto, kernel=poly;, score=0.742 total time=  11.3s\n",
            "[CV 1/2] END C=0.1, degree=1, gamma=auto, kernel=rbf;, score=0.742 total time=  14.6s\n",
            "[CV 2/2] END C=0.1, degree=1, gamma=auto, kernel=rbf;, score=0.742 total time=  15.3s\n",
            "[CV 1/2] END C=0.1, degree=1, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.4s\n",
            "[CV 2/2] END C=0.1, degree=1, gamma=auto, kernel=sigmoid;, score=0.742 total time=  12.0s\n",
            "[CV 1/2] END C=0.1, degree=2, gamma=scale, kernel=linear;, score=0.563 total time=   2.4s\n",
            "[CV 2/2] END C=0.1, degree=2, gamma=scale, kernel=linear;, score=0.769 total time=  11.7s\n",
            "[CV 1/2] END C=0.1, degree=2, gamma=scale, kernel=poly;, score=0.500 total time=  11.3s\n",
            "[CV 2/2] END C=0.1, degree=2, gamma=scale, kernel=poly;, score=0.744 total time=  13.5s\n",
            "[CV 1/2] END C=0.1, degree=2, gamma=scale, kernel=rbf;, score=0.576 total time=   8.0s\n",
            "[CV 2/2] END C=0.1, degree=2, gamma=scale, kernel=rbf;, score=0.742 total time=  15.7s\n",
            "[CV 1/2] END C=0.1, degree=2, gamma=scale, kernel=sigmoid;, score=0.756 total time=  11.2s\n",
            "[CV 2/2] END C=0.1, degree=2, gamma=scale, kernel=sigmoid;, score=0.742 total time=  12.4s\n",
            "[CV 1/2] END C=0.1, degree=2, gamma=auto, kernel=linear;, score=0.563 total time=   2.4s\n",
            "[CV 2/2] END C=0.1, degree=2, gamma=auto, kernel=linear;, score=0.769 total time=  11.4s\n",
            "[CV 1/2] END C=0.1, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  11.2s\n",
            "[CV 2/2] END C=0.1, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  11.1s\n",
            "[CV 1/2] END C=0.1, degree=2, gamma=auto, kernel=rbf;, score=0.742 total time=  14.5s\n",
            "[CV 2/2] END C=0.1, degree=2, gamma=auto, kernel=rbf;, score=0.742 total time=  14.9s\n",
            "[CV 1/2] END C=0.1, degree=2, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.3s\n",
            "[CV 2/2] END C=0.1, degree=2, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.2s\n",
            "[CV 1/2] END C=0.1, degree=3, gamma=scale, kernel=linear;, score=0.563 total time=   2.2s\n",
            "[CV 2/2] END C=0.1, degree=3, gamma=scale, kernel=linear;, score=0.769 total time=  11.0s\n",
            "[CV 1/2] END C=0.1, degree=3, gamma=scale, kernel=poly;, score=0.492 total time=  11.1s\n",
            "[CV 2/2] END C=0.1, degree=3, gamma=scale, kernel=poly;, score=0.744 total time=  14.2s\n",
            "[CV 1/2] END C=0.1, degree=3, gamma=scale, kernel=rbf;, score=0.576 total time=   7.8s\n",
            "[CV 2/2] END C=0.1, degree=3, gamma=scale, kernel=rbf;, score=0.742 total time=  15.6s\n",
            "[CV 1/2] END C=0.1, degree=3, gamma=scale, kernel=sigmoid;, score=0.756 total time=  11.0s\n",
            "[CV 2/2] END C=0.1, degree=3, gamma=scale, kernel=sigmoid;, score=0.742 total time=  11.8s\n",
            "[CV 1/2] END C=0.1, degree=3, gamma=auto, kernel=linear;, score=0.563 total time=   2.3s\n",
            "[CV 2/2] END C=0.1, degree=3, gamma=auto, kernel=linear;, score=0.769 total time=  11.0s\n",
            "[CV 1/2] END C=0.1, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  11.1s\n",
            "[CV 2/2] END C=0.1, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  11.2s\n",
            "[CV 1/2] END C=0.1, degree=3, gamma=auto, kernel=rbf;, score=0.742 total time=  14.4s\n",
            "[CV 2/2] END C=0.1, degree=3, gamma=auto, kernel=rbf;, score=0.742 total time=  14.7s\n",
            "[CV 1/2] END C=0.1, degree=3, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.1s\n",
            "[CV 2/2] END C=0.1, degree=3, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.3s\n",
            "[CV 1/2] END C=0.1, degree=4, gamma=scale, kernel=linear;, score=0.563 total time=   2.4s\n",
            "[CV 2/2] END C=0.1, degree=4, gamma=scale, kernel=linear;, score=0.769 total time=  11.1s\n",
            "[CV 1/2] END C=0.1, degree=4, gamma=scale, kernel=poly;, score=0.492 total time=  10.0s\n",
            "[CV 2/2] END C=0.1, degree=4, gamma=scale, kernel=poly;, score=0.744 total time=  14.9s\n",
            "[CV 1/2] END C=0.1, degree=4, gamma=scale, kernel=rbf;, score=0.576 total time=   8.0s\n",
            "[CV 2/2] END C=0.1, degree=4, gamma=scale, kernel=rbf;, score=0.742 total time=  15.7s\n",
            "[CV 1/2] END C=0.1, degree=4, gamma=scale, kernel=sigmoid;, score=0.756 total time=  11.3s\n",
            "[CV 2/2] END C=0.1, degree=4, gamma=scale, kernel=sigmoid;, score=0.742 total time=  12.2s\n",
            "[CV 1/2] END C=0.1, degree=4, gamma=auto, kernel=linear;, score=0.563 total time=   2.3s\n",
            "[CV 2/2] END C=0.1, degree=4, gamma=auto, kernel=linear;, score=0.769 total time=  11.5s\n",
            "[CV 1/2] END C=0.1, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  11.0s\n",
            "[CV 2/2] END C=0.1, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  11.2s\n",
            "[CV 1/2] END C=0.1, degree=4, gamma=auto, kernel=rbf;, score=0.742 total time=  14.7s\n",
            "[CV 2/2] END C=0.1, degree=4, gamma=auto, kernel=rbf;, score=0.742 total time=  14.8s\n",
            "[CV 1/2] END C=0.1, degree=4, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.1s\n",
            "[CV 2/2] END C=0.1, degree=4, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.5s\n",
            "[CV 1/2] END C=0.1, degree=5, gamma=scale, kernel=linear;, score=0.563 total time=   2.3s\n",
            "[CV 2/2] END C=0.1, degree=5, gamma=scale, kernel=linear;, score=0.769 total time=  11.6s\n",
            "[CV 1/2] END C=0.1, degree=5, gamma=scale, kernel=poly;, score=0.492 total time=   9.6s\n",
            "[CV 2/2] END C=0.1, degree=5, gamma=scale, kernel=poly;, score=0.744 total time=  15.4s\n",
            "[CV 1/2] END C=0.1, degree=5, gamma=scale, kernel=rbf;, score=0.576 total time=   7.8s\n",
            "[CV 2/2] END C=0.1, degree=5, gamma=scale, kernel=rbf;, score=0.742 total time=  16.0s\n",
            "[CV 1/2] END C=0.1, degree=5, gamma=scale, kernel=sigmoid;, score=0.756 total time=  11.6s\n",
            "[CV 2/2] END C=0.1, degree=5, gamma=scale, kernel=sigmoid;, score=0.742 total time=  12.3s\n",
            "[CV 1/2] END C=0.1, degree=5, gamma=auto, kernel=linear;, score=0.563 total time=   2.3s\n",
            "[CV 2/2] END C=0.1, degree=5, gamma=auto, kernel=linear;, score=0.769 total time=  11.3s\n",
            "[CV 1/2] END C=0.1, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  11.1s\n",
            "[CV 2/2] END C=0.1, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  11.6s\n",
            "[CV 1/2] END C=0.1, degree=5, gamma=auto, kernel=rbf;, score=0.742 total time=  15.0s\n",
            "[CV 2/2] END C=0.1, degree=5, gamma=auto, kernel=rbf;, score=0.742 total time=  15.5s\n",
            "[CV 1/2] END C=0.1, degree=5, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.8s\n",
            "[CV 2/2] END C=0.1, degree=5, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.5s\n",
            "[CV 1/2] END C=1, degree=1, gamma=scale, kernel=linear;, score=0.571 total time=   1.6s\n",
            "[CV 2/2] END C=1, degree=1, gamma=scale, kernel=linear;, score=0.770 total time=   9.7s\n",
            "[CV 1/2] END C=1, degree=1, gamma=scale, kernel=poly;, score=0.562 total time=   3.8s\n",
            "[CV 2/2] END C=1, degree=1, gamma=scale, kernel=poly;, score=0.786 total time=  11.9s\n",
            "[CV 1/2] END C=1, degree=1, gamma=scale, kernel=rbf;, score=0.580 total time=   3.1s\n",
            "[CV 2/2] END C=1, degree=1, gamma=scale, kernel=rbf;, score=0.797 total time=  15.3s\n",
            "[CV 1/2] END C=1, degree=1, gamma=scale, kernel=sigmoid;, score=0.562 total time=   4.3s\n",
            "[CV 2/2] END C=1, degree=1, gamma=scale, kernel=sigmoid;, score=0.784 total time=  11.4s\n",
            "[CV 1/2] END C=1, degree=1, gamma=auto, kernel=linear;, score=0.571 total time=   1.5s\n",
            "[CV 2/2] END C=1, degree=1, gamma=auto, kernel=linear;, score=0.770 total time=   9.9s\n",
            "[CV 1/2] END C=1, degree=1, gamma=auto, kernel=poly;, score=0.742 total time=  11.6s\n",
            "[CV 2/2] END C=1, degree=1, gamma=auto, kernel=poly;, score=0.742 total time=  12.4s\n",
            "[CV 1/2] END C=1, degree=1, gamma=auto, kernel=rbf;, score=0.742 total time=  15.0s\n",
            "[CV 2/2] END C=1, degree=1, gamma=auto, kernel=rbf;, score=0.742 total time=  16.0s\n",
            "[CV 1/2] END C=1, degree=1, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.8s\n",
            "[CV 2/2] END C=1, degree=1, gamma=auto, kernel=sigmoid;, score=0.742 total time=  12.8s\n",
            "[CV 1/2] END C=1, degree=2, gamma=scale, kernel=linear;, score=0.571 total time=   1.5s\n",
            "[CV 2/2] END C=1, degree=2, gamma=scale, kernel=linear;, score=0.770 total time=   9.7s\n",
            "[CV 1/2] END C=1, degree=2, gamma=scale, kernel=poly;, score=0.558 total time=   7.0s\n",
            "[CV 2/2] END C=1, degree=2, gamma=scale, kernel=poly;, score=0.746 total time=  13.9s\n",
            "[CV 1/2] END C=1, degree=2, gamma=scale, kernel=rbf;, score=0.580 total time=   3.1s\n",
            "[CV 2/2] END C=1, degree=2, gamma=scale, kernel=rbf;, score=0.797 total time=  16.0s\n",
            "[CV 1/2] END C=1, degree=2, gamma=scale, kernel=sigmoid;, score=0.562 total time=   4.8s\n",
            "[CV 2/2] END C=1, degree=2, gamma=scale, kernel=sigmoid;, score=0.784 total time=  11.8s\n",
            "[CV 1/2] END C=1, degree=2, gamma=auto, kernel=linear;, score=0.571 total time=   1.5s\n",
            "[CV 2/2] END C=1, degree=2, gamma=auto, kernel=linear;, score=0.770 total time=  10.0s\n",
            "[CV 1/2] END C=1, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  11.6s\n",
            "[CV 2/2] END C=1, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  11.2s\n",
            "[CV 1/2] END C=1, degree=2, gamma=auto, kernel=rbf;, score=0.742 total time=  15.0s\n",
            "[CV 2/2] END C=1, degree=2, gamma=auto, kernel=rbf;, score=0.742 total time=  16.1s\n",
            "[CV 1/2] END C=1, degree=2, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.4s\n",
            "[CV 2/2] END C=1, degree=2, gamma=auto, kernel=sigmoid;, score=0.742 total time=  11.8s\n",
            "[CV 1/2] END C=1, degree=3, gamma=scale, kernel=linear;, score=0.571 total time=   1.6s\n",
            "[CV 2/2] END C=1, degree=3, gamma=scale, kernel=linear;, score=0.770 total time=   9.5s\n",
            "[CV 1/2] END C=1, degree=3, gamma=scale, kernel=poly;, score=0.534 total time=   8.2s\n",
            "[CV 2/2] END C=1, degree=3, gamma=scale, kernel=poly;, score=0.744 total time=  14.6s\n",
            "[CV 1/2] END C=1, degree=3, gamma=scale, kernel=rbf;, score=0.580 total time=   3.1s\n",
            "[CV 2/2] END C=1, degree=3, gamma=scale, kernel=rbf;, score=0.797 total time=  15.7s\n",
            "[CV 1/2] END C=1, degree=3, gamma=scale, kernel=sigmoid;, score=0.562 total time=   4.9s\n",
            "[CV 2/2] END C=1, degree=3, gamma=scale, kernel=sigmoid;, score=0.784 total time=  12.7s\n",
            "[CV 1/2] END C=1, degree=3, gamma=auto, kernel=linear;, score=0.571 total time=   1.6s\n",
            "[CV 2/2] END C=1, degree=3, gamma=auto, kernel=linear;, score=0.770 total time=  10.7s\n",
            "[CV 1/2] END C=1, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  12.5s\n",
            "[CV 2/2] END C=1, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  12.5s\n",
            "[CV 1/2] END C=1, degree=3, gamma=auto, kernel=rbf;, score=0.742 total time=  15.7s\n",
            "[CV 2/2] END C=1, degree=3, gamma=auto, kernel=rbf;, score=0.742 total time=  16.6s\n",
            "[CV 1/2] END C=1, degree=3, gamma=auto, kernel=sigmoid;, score=0.742 total time=  12.7s\n",
            "[CV 2/2] END C=1, degree=3, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.7s\n",
            "[CV 1/2] END C=1, degree=4, gamma=scale, kernel=linear;, score=0.571 total time=   1.6s\n",
            "[CV 2/2] END C=1, degree=4, gamma=scale, kernel=linear;, score=0.770 total time=  11.0s\n",
            "[CV 1/2] END C=1, degree=4, gamma=scale, kernel=poly;, score=0.512 total time=   9.1s\n",
            "[CV 2/2] END C=1, degree=4, gamma=scale, kernel=poly;, score=0.744 total time=  16.3s\n",
            "[CV 1/2] END C=1, degree=4, gamma=scale, kernel=rbf;, score=0.580 total time=   3.1s\n",
            "[CV 2/2] END C=1, degree=4, gamma=scale, kernel=rbf;, score=0.797 total time=  15.9s\n",
            "[CV 1/2] END C=1, degree=4, gamma=scale, kernel=sigmoid;, score=0.562 total time=   5.3s\n",
            "[CV 2/2] END C=1, degree=4, gamma=scale, kernel=sigmoid;, score=0.784 total time=  12.5s\n",
            "[CV 1/2] END C=1, degree=4, gamma=auto, kernel=linear;, score=0.571 total time=   1.5s\n",
            "[CV 2/2] END C=1, degree=4, gamma=auto, kernel=linear;, score=0.770 total time=  10.5s\n",
            "[CV 1/2] END C=1, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  12.8s\n",
            "[CV 2/2] END C=1, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  12.0s\n",
            "[CV 1/2] END C=1, degree=4, gamma=auto, kernel=rbf;, score=0.742 total time=  16.1s\n",
            "[CV 2/2] END C=1, degree=4, gamma=auto, kernel=rbf;, score=0.742 total time=  16.5s\n",
            "[CV 1/2] END C=1, degree=4, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.2s\n",
            "[CV 2/2] END C=1, degree=4, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.5s\n",
            "[CV 1/2] END C=1, degree=5, gamma=scale, kernel=linear;, score=0.571 total time=   1.7s\n",
            "[CV 2/2] END C=1, degree=5, gamma=scale, kernel=linear;, score=0.770 total time=  11.0s\n",
            "[CV 1/2] END C=1, degree=5, gamma=scale, kernel=poly;, score=0.511 total time=   8.4s\n",
            "[CV 2/2] END C=1, degree=5, gamma=scale, kernel=poly;, score=0.744 total time=  16.0s\n",
            "[CV 1/2] END C=1, degree=5, gamma=scale, kernel=rbf;, score=0.580 total time=   3.2s\n",
            "[CV 2/2] END C=1, degree=5, gamma=scale, kernel=rbf;, score=0.797 total time=  16.1s\n",
            "[CV 1/2] END C=1, degree=5, gamma=scale, kernel=sigmoid;, score=0.562 total time=   4.8s\n",
            "[CV 2/2] END C=1, degree=5, gamma=scale, kernel=sigmoid;, score=0.784 total time=  12.2s\n",
            "[CV 1/2] END C=1, degree=5, gamma=auto, kernel=linear;, score=0.571 total time=   1.6s\n",
            "[CV 2/2] END C=1, degree=5, gamma=auto, kernel=linear;, score=0.770 total time=  10.3s\n",
            "[CV 1/2] END C=1, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  12.7s\n",
            "[CV 2/2] END C=1, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  11.9s\n",
            "[CV 1/2] END C=1, degree=5, gamma=auto, kernel=rbf;, score=0.742 total time=  15.8s\n",
            "[CV 2/2] END C=1, degree=5, gamma=auto, kernel=rbf;, score=0.742 total time=  16.5s\n",
            "[CV 1/2] END C=1, degree=5, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.2s\n",
            "[CV 2/2] END C=1, degree=5, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.1s\n",
            "[CV 1/2] END C=10, degree=1, gamma=scale, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=10, degree=1, gamma=scale, kernel=linear;, score=0.787 total time=   9.5s\n",
            "[CV 1/2] END C=10, degree=1, gamma=scale, kernel=poly;, score=0.567 total time=   1.9s\n",
            "[CV 2/2] END C=10, degree=1, gamma=scale, kernel=poly;, score=0.776 total time=  10.5s\n",
            "[CV 1/2] END C=10, degree=1, gamma=scale, kernel=rbf;, score=0.591 total time=   1.9s\n",
            "[CV 2/2] END C=10, degree=1, gamma=scale, kernel=rbf;, score=0.842 total time=  14.3s\n",
            "[CV 1/2] END C=10, degree=1, gamma=scale, kernel=sigmoid;, score=0.568 total time=   2.0s\n",
            "[CV 2/2] END C=10, degree=1, gamma=scale, kernel=sigmoid;, score=0.705 total time=  10.6s\n",
            "[CV 1/2] END C=10, degree=1, gamma=auto, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=10, degree=1, gamma=auto, kernel=linear;, score=0.787 total time=   9.6s\n",
            "[CV 1/2] END C=10, degree=1, gamma=auto, kernel=poly;, score=0.555 total time=  12.9s\n",
            "[CV 2/2] END C=10, degree=1, gamma=auto, kernel=poly;, score=0.742 total time=  13.9s\n",
            "[CV 1/2] END C=10, degree=1, gamma=auto, kernel=rbf;, score=0.565 total time=  12.1s\n",
            "[CV 2/2] END C=10, degree=1, gamma=auto, kernel=rbf;, score=0.744 total time=  17.3s\n",
            "[CV 1/2] END C=10, degree=1, gamma=auto, kernel=sigmoid;, score=0.555 total time=  13.2s\n",
            "[CV 2/2] END C=10, degree=1, gamma=auto, kernel=sigmoid;, score=0.742 total time=  14.0s\n",
            "[CV 1/2] END C=10, degree=2, gamma=scale, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=10, degree=2, gamma=scale, kernel=linear;, score=0.787 total time=   9.6s\n",
            "[CV 1/2] END C=10, degree=2, gamma=scale, kernel=poly;, score=0.563 total time=   2.9s\n",
            "[CV 2/2] END C=10, degree=2, gamma=scale, kernel=poly;, score=0.782 total time=  14.5s\n",
            "[CV 1/2] END C=10, degree=2, gamma=scale, kernel=rbf;, score=0.591 total time=   1.9s\n",
            "[CV 2/2] END C=10, degree=2, gamma=scale, kernel=rbf;, score=0.842 total time=  14.4s\n",
            "[CV 1/2] END C=10, degree=2, gamma=scale, kernel=sigmoid;, score=0.568 total time=   2.0s\n",
            "[CV 2/2] END C=10, degree=2, gamma=scale, kernel=sigmoid;, score=0.705 total time=  10.6s\n",
            "[CV 1/2] END C=10, degree=2, gamma=auto, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=10, degree=2, gamma=auto, kernel=linear;, score=0.787 total time=   9.5s\n",
            "[CV 1/2] END C=10, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  12.2s\n",
            "[CV 2/2] END C=10, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  11.4s\n",
            "[CV 1/2] END C=10, degree=2, gamma=auto, kernel=rbf;, score=0.565 total time=  11.7s\n",
            "[CV 2/2] END C=10, degree=2, gamma=auto, kernel=rbf;, score=0.744 total time=  16.3s\n",
            "[CV 1/2] END C=10, degree=2, gamma=auto, kernel=sigmoid;, score=0.555 total time=  13.1s\n",
            "[CV 2/2] END C=10, degree=2, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.0s\n",
            "[CV 1/2] END C=10, degree=3, gamma=scale, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=10, degree=3, gamma=scale, kernel=linear;, score=0.787 total time=   9.5s\n",
            "[CV 1/2] END C=10, degree=3, gamma=scale, kernel=poly;, score=0.562 total time=   5.8s\n",
            "[CV 2/2] END C=10, degree=3, gamma=scale, kernel=poly;, score=0.753 total time=  15.6s\n",
            "[CV 1/2] END C=10, degree=3, gamma=scale, kernel=rbf;, score=0.591 total time=   1.9s\n",
            "[CV 2/2] END C=10, degree=3, gamma=scale, kernel=rbf;, score=0.842 total time=  14.4s\n",
            "[CV 1/2] END C=10, degree=3, gamma=scale, kernel=sigmoid;, score=0.568 total time=   2.0s\n",
            "[CV 2/2] END C=10, degree=3, gamma=scale, kernel=sigmoid;, score=0.705 total time=  10.6s\n",
            "[CV 1/2] END C=10, degree=3, gamma=auto, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=10, degree=3, gamma=auto, kernel=linear;, score=0.787 total time=   9.9s\n",
            "[CV 1/2] END C=10, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  12.8s\n",
            "[CV 2/2] END C=10, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  12.2s\n",
            "[CV 1/2] END C=10, degree=3, gamma=auto, kernel=rbf;, score=0.565 total time=  12.1s\n",
            "[CV 2/2] END C=10, degree=3, gamma=auto, kernel=rbf;, score=0.744 total time=  16.5s\n",
            "[CV 1/2] END C=10, degree=3, gamma=auto, kernel=sigmoid;, score=0.555 total time=  13.3s\n",
            "[CV 2/2] END C=10, degree=3, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.3s\n",
            "[CV 1/2] END C=10, degree=4, gamma=scale, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=10, degree=4, gamma=scale, kernel=linear;, score=0.787 total time=   9.7s\n",
            "[CV 1/2] END C=10, degree=4, gamma=scale, kernel=poly;, score=0.546 total time=   8.1s\n",
            "[CV 2/2] END C=10, degree=4, gamma=scale, kernel=poly;, score=0.747 total time=  16.5s\n",
            "[CV 1/2] END C=10, degree=4, gamma=scale, kernel=rbf;, score=0.591 total time=   1.9s\n",
            "[CV 2/2] END C=10, degree=4, gamma=scale, kernel=rbf;, score=0.842 total time=  14.8s\n",
            "[CV 1/2] END C=10, degree=4, gamma=scale, kernel=sigmoid;, score=0.568 total time=   2.0s\n",
            "[CV 2/2] END C=10, degree=4, gamma=scale, kernel=sigmoid;, score=0.705 total time=  11.5s\n",
            "[CV 1/2] END C=10, degree=4, gamma=auto, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=10, degree=4, gamma=auto, kernel=linear;, score=0.787 total time=  10.2s\n",
            "[CV 1/2] END C=10, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  12.9s\n",
            "[CV 2/2] END C=10, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  13.2s\n",
            "[CV 1/2] END C=10, degree=4, gamma=auto, kernel=rbf;, score=0.565 total time=  12.7s\n",
            "[CV 2/2] END C=10, degree=4, gamma=auto, kernel=rbf;, score=0.744 total time=  17.7s\n",
            "[CV 1/2] END C=10, degree=4, gamma=auto, kernel=sigmoid;, score=0.555 total time=  13.2s\n",
            "[CV 2/2] END C=10, degree=4, gamma=auto, kernel=sigmoid;, score=0.742 total time=  14.1s\n",
            "[CV 1/2] END C=10, degree=5, gamma=scale, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=10, degree=5, gamma=scale, kernel=linear;, score=0.787 total time=  10.1s\n",
            "[CV 1/2] END C=10, degree=5, gamma=scale, kernel=poly;, score=0.516 total time=   8.9s\n",
            "[CV 2/2] END C=10, degree=5, gamma=scale, kernel=poly;, score=0.744 total time=  17.1s\n",
            "[CV 1/2] END C=10, degree=5, gamma=scale, kernel=rbf;, score=0.591 total time=   1.9s\n",
            "[CV 2/2] END C=10, degree=5, gamma=scale, kernel=rbf;, score=0.842 total time=  14.3s\n",
            "[CV 1/2] END C=10, degree=5, gamma=scale, kernel=sigmoid;, score=0.568 total time=   2.1s\n",
            "[CV 2/2] END C=10, degree=5, gamma=scale, kernel=sigmoid;, score=0.705 total time=  10.5s\n",
            "[CV 1/2] END C=10, degree=5, gamma=auto, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=10, degree=5, gamma=auto, kernel=linear;, score=0.787 total time=   9.3s\n",
            "[CV 1/2] END C=10, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  12.6s\n",
            "[CV 2/2] END C=10, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  11.8s\n",
            "[CV 1/2] END C=10, degree=5, gamma=auto, kernel=rbf;, score=0.565 total time=  12.2s\n",
            "[CV 2/2] END C=10, degree=5, gamma=auto, kernel=rbf;, score=0.744 total time=  16.4s\n",
            "[CV 1/2] END C=10, degree=5, gamma=auto, kernel=sigmoid;, score=0.555 total time=  13.1s\n",
            "[CV 2/2] END C=10, degree=5, gamma=auto, kernel=sigmoid;, score=0.742 total time=  13.5s\n",
            "[CV 1/2] END C=100, degree=1, gamma=scale, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=100, degree=1, gamma=scale, kernel=linear;, score=0.765 total time=  11.6s\n",
            "[CV 1/2] END C=100, degree=1, gamma=scale, kernel=poly;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=100, degree=1, gamma=scale, kernel=poly;, score=0.789 total time=   9.9s\n",
            "[CV 1/2] END C=100, degree=1, gamma=scale, kernel=rbf;, score=0.595 total time=   1.8s\n",
            "[CV 2/2] END C=100, degree=1, gamma=scale, kernel=rbf;, score=0.843 total time=  12.1s\n",
            "[CV 1/2] END C=100, degree=1, gamma=scale, kernel=sigmoid;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=100, degree=1, gamma=scale, kernel=sigmoid;, score=0.770 total time=   8.5s\n",
            "[CV 1/2] END C=100, degree=1, gamma=auto, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=100, degree=1, gamma=auto, kernel=linear;, score=0.765 total time=  11.0s\n",
            "[CV 1/2] END C=100, degree=1, gamma=auto, kernel=poly;, score=0.562 total time=   3.6s\n",
            "[CV 2/2] END C=100, degree=1, gamma=auto, kernel=poly;, score=0.771 total time=  12.1s\n",
            "[CV 1/2] END C=100, degree=1, gamma=auto, kernel=rbf;, score=0.570 total time=   3.5s\n",
            "[CV 2/2] END C=100, degree=1, gamma=auto, kernel=rbf;, score=0.777 total time=  15.6s\n",
            "[CV 1/2] END C=100, degree=1, gamma=auto, kernel=sigmoid;, score=0.562 total time=   3.7s\n",
            "[CV 2/2] END C=100, degree=1, gamma=auto, kernel=sigmoid;, score=0.771 total time=  12.8s\n",
            "[CV 1/2] END C=100, degree=2, gamma=scale, kernel=linear;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=100, degree=2, gamma=scale, kernel=linear;, score=0.765 total time=  11.2s\n",
            "[CV 1/2] END C=100, degree=2, gamma=scale, kernel=poly;, score=0.564 total time=   2.1s\n",
            "[CV 2/2] END C=100, degree=2, gamma=scale, kernel=poly;, score=0.792 total time=  11.9s\n",
            "[CV 1/2] END C=100, degree=2, gamma=scale, kernel=rbf;, score=0.595 total time=   1.7s\n",
            "[CV 2/2] END C=100, degree=2, gamma=scale, kernel=rbf;, score=0.843 total time=  12.3s\n",
            "[CV 1/2] END C=100, degree=2, gamma=scale, kernel=sigmoid;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=100, degree=2, gamma=scale, kernel=sigmoid;, score=0.770 total time=   8.4s\n",
            "[CV 1/2] END C=100, degree=2, gamma=auto, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=100, degree=2, gamma=auto, kernel=linear;, score=0.765 total time=  11.0s\n",
            "[CV 1/2] END C=100, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  11.6s\n",
            "[CV 2/2] END C=100, degree=2, gamma=auto, kernel=poly;, score=0.742 total time=  13.0s\n",
            "[CV 1/2] END C=100, degree=2, gamma=auto, kernel=rbf;, score=0.570 total time=   3.6s\n",
            "[CV 2/2] END C=100, degree=2, gamma=auto, kernel=rbf;, score=0.777 total time=  15.5s\n",
            "[CV 1/2] END C=100, degree=2, gamma=auto, kernel=sigmoid;, score=0.562 total time=   3.7s\n",
            "[CV 2/2] END C=100, degree=2, gamma=auto, kernel=sigmoid;, score=0.771 total time=  12.4s\n",
            "[CV 1/2] END C=100, degree=3, gamma=scale, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=100, degree=3, gamma=scale, kernel=linear;, score=0.765 total time=  11.1s\n",
            "[CV 1/2] END C=100, degree=3, gamma=scale, kernel=poly;, score=0.563 total time=   2.5s\n",
            "[CV 2/2] END C=100, degree=3, gamma=scale, kernel=poly;, score=0.782 total time=  13.7s\n",
            "[CV 1/2] END C=100, degree=3, gamma=scale, kernel=rbf;, score=0.595 total time=   1.7s\n",
            "[CV 2/2] END C=100, degree=3, gamma=scale, kernel=rbf;, score=0.843 total time=  12.1s\n",
            "[CV 1/2] END C=100, degree=3, gamma=scale, kernel=sigmoid;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=100, degree=3, gamma=scale, kernel=sigmoid;, score=0.770 total time=   8.4s\n",
            "[CV 1/2] END C=100, degree=3, gamma=auto, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=100, degree=3, gamma=auto, kernel=linear;, score=0.765 total time=  11.1s\n",
            "[CV 1/2] END C=100, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  11.3s\n",
            "[CV 2/2] END C=100, degree=3, gamma=auto, kernel=poly;, score=0.742 total time=  11.2s\n",
            "[CV 1/2] END C=100, degree=3, gamma=auto, kernel=rbf;, score=0.570 total time=   3.5s\n",
            "[CV 2/2] END C=100, degree=3, gamma=auto, kernel=rbf;, score=0.777 total time=  14.9s\n",
            "[CV 1/2] END C=100, degree=3, gamma=auto, kernel=sigmoid;, score=0.562 total time=   3.5s\n",
            "[CV 2/2] END C=100, degree=3, gamma=auto, kernel=sigmoid;, score=0.771 total time=  11.9s\n",
            "[CV 1/2] END C=100, degree=4, gamma=scale, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=100, degree=4, gamma=scale, kernel=linear;, score=0.765 total time=  10.8s\n",
            "[CV 1/2] END C=100, degree=4, gamma=scale, kernel=poly;, score=0.562 total time=   3.5s\n",
            "[CV 2/2] END C=100, degree=4, gamma=scale, kernel=poly;, score=0.757 total time=  14.1s\n",
            "[CV 1/2] END C=100, degree=4, gamma=scale, kernel=rbf;, score=0.595 total time=   1.8s\n",
            "[CV 2/2] END C=100, degree=4, gamma=scale, kernel=rbf;, score=0.843 total time=  12.3s\n",
            "[CV 1/2] END C=100, degree=4, gamma=scale, kernel=sigmoid;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=100, degree=4, gamma=scale, kernel=sigmoid;, score=0.770 total time=   8.3s\n",
            "[CV 1/2] END C=100, degree=4, gamma=auto, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=100, degree=4, gamma=auto, kernel=linear;, score=0.765 total time=  10.9s\n",
            "[CV 1/2] END C=100, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  11.1s\n",
            "[CV 2/2] END C=100, degree=4, gamma=auto, kernel=poly;, score=0.742 total time=  11.1s\n",
            "[CV 1/2] END C=100, degree=4, gamma=auto, kernel=rbf;, score=0.570 total time=   3.5s\n",
            "[CV 2/2] END C=100, degree=4, gamma=auto, kernel=rbf;, score=0.777 total time=  15.3s\n",
            "[CV 1/2] END C=100, degree=4, gamma=auto, kernel=sigmoid;, score=0.562 total time=   3.6s\n",
            "[CV 2/2] END C=100, degree=4, gamma=auto, kernel=sigmoid;, score=0.771 total time=  12.2s\n",
            "[CV 1/2] END C=100, degree=5, gamma=scale, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=100, degree=5, gamma=scale, kernel=linear;, score=0.765 total time=  10.8s\n",
            "[CV 1/2] END C=100, degree=5, gamma=scale, kernel=poly;, score=0.550 total time=   6.4s\n",
            "[CV 2/2] END C=100, degree=5, gamma=scale, kernel=poly;, score=0.748 total time=  15.4s\n",
            "[CV 1/2] END C=100, degree=5, gamma=scale, kernel=rbf;, score=0.595 total time=   1.7s\n",
            "[CV 2/2] END C=100, degree=5, gamma=scale, kernel=rbf;, score=0.843 total time=  11.9s\n",
            "[CV 1/2] END C=100, degree=5, gamma=scale, kernel=sigmoid;, score=0.574 total time=   1.5s\n",
            "[CV 2/2] END C=100, degree=5, gamma=scale, kernel=sigmoid;, score=0.770 total time=   8.1s\n",
            "[CV 1/2] END C=100, degree=5, gamma=auto, kernel=linear;, score=0.574 total time=   1.4s\n",
            "[CV 2/2] END C=100, degree=5, gamma=auto, kernel=linear;, score=0.765 total time=  10.8s\n",
            "[CV 1/2] END C=100, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  11.1s\n",
            "[CV 2/2] END C=100, degree=5, gamma=auto, kernel=poly;, score=0.742 total time=  10.9s\n",
            "[CV 1/2] END C=100, degree=5, gamma=auto, kernel=rbf;, score=0.570 total time=   3.7s\n",
            "[CV 2/2] END C=100, degree=5, gamma=auto, kernel=rbf;, score=0.777 total time=  15.0s\n",
            "[CV 1/2] END C=100, degree=5, gamma=auto, kernel=sigmoid;, score=0.562 total time=   3.9s\n",
            "[CV 2/2] END C=100, degree=5, gamma=auto, kernel=sigmoid;, score=0.771 total time=  12.5s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=SVC(),\n",
              "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
              "                         'degree': [1, 2, 3, 4, 5], 'gamma': ['scale', 'auto'],\n",
              "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
              "             verbose=3)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters = {\n",
        "    'C':[0.01,0.1,1,10,100],\n",
        "    'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'degree': list(np.arange(1,6,1)),\n",
        "    'gamma': ['scale', 'auto'],\n",
        "}\n",
        "svc = SVC()\n",
        "clf = GridSearchCV(svc, parameters, verbose=3, cv=2)\n",
        "clf.fit(df_vector, Class_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UhYXz17K6vcy",
        "outputId": "b73963cd-f1a1-4e59-b5a7-34e7d895f34d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parameter terbaik :  {'C': 0.1, 'degree': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "Akurasi parameter :  0.748927002372543\n"
          ]
        }
      ],
      "source": [
        "print('parameter terbaik : ',clf.best_params_)\n",
        "print('Akurasi parameter : ',clf.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXQSBKKu876e"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sDuoTqUXUcEd",
        "outputId": "7db7a8dc-391c-463d-acbd-6cfed6dc083e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold ke =  1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      1.00      0.85       656\n",
            "           1       0.00      0.00      0.00       231\n",
            "\n",
            "    accuracy                           0.74       887\n",
            "   macro avg       0.37      0.50      0.43       887\n",
            "weighted avg       0.55      0.74      0.63       887\n",
            "\n",
            "Accuracy : 73.957 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      1.00      0.84       642\n",
            "           1       0.00      0.00      0.00       245\n",
            "\n",
            "    accuracy                           0.72       887\n",
            "   macro avg       0.36      0.50      0.42       887\n",
            "weighted avg       0.52      0.72      0.61       887\n",
            "\n",
            "Accuracy : 72.379 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86       666\n",
            "           1       1.00      0.00      0.01       221\n",
            "\n",
            "    accuracy                           0.75       887\n",
            "   macro avg       0.88      0.50      0.43       887\n",
            "weighted avg       0.81      0.75      0.65       887\n",
            "\n",
            "Accuracy : 75.197 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.85       660\n",
            "           1       1.00      0.00      0.01       226\n",
            "\n",
            "    accuracy                           0.75       886\n",
            "   macro avg       0.87      0.50      0.43       886\n",
            "weighted avg       0.81      0.75      0.64       886\n",
            "\n",
            "Accuracy : 74.605 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86       667\n",
            "           1       1.00      0.00      0.01       219\n",
            "\n",
            "    accuracy                           0.75       886\n",
            "   macro avg       0.88      0.50      0.43       886\n",
            "weighted avg       0.81      0.75      0.65       886\n",
            "\n",
            "Accuracy : 75.395 %\n",
            "--------------------------------------------------\n",
            "Rata-rata akurasi metode : 74.307 %\n"
          ]
        }
      ],
      "source": [
        "n_fold = 1\n",
        "akurasi = []\n",
        "for train_index, test_index in kf.split(df_vector):\n",
        "  print('Fold ke = ',n_fold)\n",
        "  x_train, x_test = df_vector.iloc[train_index], df_vector.iloc[test_index]\n",
        "  y_train, y_test = Class_encoder[train_index], Class_encoder[test_index]\n",
        "\n",
        "  SVC_model = SVC(**clf.best_params_)\n",
        "  SVC_model.fit(x_train,y_train)\n",
        "  SVC_pred = SVC_model.predict(x_test)\n",
        "\n",
        "  print(classification_report(y_test,SVC_pred))\n",
        "\n",
        "  unique, counts = np.unique((y_test == SVC_pred.reshape(SVC_pred.shape[0],)), return_counts=True)\n",
        "  acc = (counts[1]/np.sum(counts)) * 100\n",
        "  akurasi.append(acc)\n",
        "  n_fold += 1\n",
        "  print(f'Accuracy : {acc:.3f} %'.format(acc))\n",
        "  print('-'*50)\n",
        "\n",
        "print(f'Rata-rata akurasi metode : {np.mean(akurasi):.3f} %'.format(np.mean(akurasi)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3yUR8bWueM_"
      },
      "source": [
        "## MLP Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYpM6mNT8-S2"
      },
      "source": [
        "### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plAbPXu281fd",
        "outputId": "60a28ada-1030-4f19-feb9-ba1a5d411220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 200 candidates, totalling 400 fits\n",
            "[CV 1/2] END C=0.01, degree=1, gamma=scale, kernel=linear;, score=0.548 total time=   9.1s\n"
          ]
        }
      ],
      "source": [
        "parameters = {\n",
        "    'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'solver':['lbfgs', 'sgd', 'adam'],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "}\n",
        "mlp = MLPClassifier()\n",
        "clf = GridSearchCV(mlp, parameters, verbose=3, cv=2)\n",
        "clf.fit(df_vector, Class_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9Mj5DDI81fh"
      },
      "outputs": [],
      "source": [
        "print('parameter terbaik : ',clf.best_params_)\n",
        "print('Akurasi parameter : ',clf.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NItln4Vn8_6b"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUMnTUdzV564",
        "outputId": "c7ec6c55-6697-4157-c2df-4fa8ebd61429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold ke =  1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.88       656\n",
            "           1       0.69      0.48      0.57       231\n",
            "\n",
            "    accuracy                           0.81       887\n",
            "   macro avg       0.76      0.70      0.72       887\n",
            "weighted avg       0.80      0.81      0.80       887\n",
            "\n",
            "Accuracy : 80.834 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88       642\n",
            "           1       0.76      0.49      0.60       245\n",
            "\n",
            "    accuracy                           0.82       887\n",
            "   macro avg       0.79      0.72      0.74       887\n",
            "weighted avg       0.81      0.82      0.80       887\n",
            "\n",
            "Accuracy : 81.623 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91       666\n",
            "           1       0.78      0.60      0.68       221\n",
            "\n",
            "    accuracy                           0.86       887\n",
            "   macro avg       0.83      0.77      0.79       887\n",
            "weighted avg       0.85      0.86      0.85       887\n",
            "\n",
            "Accuracy : 85.795 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.89       660\n",
            "           1       0.76      0.50      0.60       226\n",
            "\n",
            "    accuracy                           0.83       886\n",
            "   macro avg       0.81      0.72      0.75       886\n",
            "weighted avg       0.83      0.83      0.82       886\n",
            "\n",
            "Accuracy : 83.296 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89       667\n",
            "           1       0.71      0.57      0.63       219\n",
            "\n",
            "    accuracy                           0.84       886\n",
            "   macro avg       0.79      0.74      0.76       886\n",
            "weighted avg       0.83      0.84      0.83       886\n",
            "\n",
            "Accuracy : 83.521 %\n",
            "--------------------------------------------------\n",
            "Rata-rata akurasi metode : 83.014 %\n"
          ]
        }
      ],
      "source": [
        "n_fold = 1\n",
        "akurasi = []\n",
        "for train_index, test_index in kf.split(df_vector):\n",
        "  print('Fold ke = ',n_fold)\n",
        "  x_train, x_test = df_vector.iloc[train_index], df_vector.iloc[test_index]\n",
        "  y_train, y_test = Class_encoder[train_index], Class_encoder[test_index]\n",
        "\n",
        "  MLP_model = MLPClassifier(random_state=42, **clf.best_params_)\n",
        "  MLP_model.fit(x_train,y_train)\n",
        "  MLP_pred = MLP_model.predict(x_test)\n",
        "\n",
        "  print(classification_report(y_test,MLP_pred))\n",
        "\n",
        "  unique, counts = np.unique((y_test == MLP_pred.reshape(MLP_pred.shape[0],)), return_counts=True)\n",
        "  acc = (counts[1]/np.sum(counts)) * 100\n",
        "  akurasi.append(acc)\n",
        "  n_fold += 1\n",
        "  print(f'Accuracy : {acc:.3f} %'.format(acc))\n",
        "  print('-'*50)\n",
        "\n",
        "print(f'Rata-rata akurasi metode : {np.mean(akurasi):.3f} %'.format(np.mean(akurasi)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGh2WF3ftWJY"
      },
      "source": [
        "## NB-SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5WwfcqcHticM"
      },
      "outputs": [],
      "source": [
        "class NBSVMClassifier(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, beta=0.5, alpha=1, C=1.0, kernel='linear', degree=3 , gamma='auto',\n",
        "                class_weight='balanced'):\n",
        "    self.C = C\n",
        "    self.kernel = kernel\n",
        "    self.degree = degree\n",
        "    self.gamma = gamma\n",
        "    self.beta = beta\n",
        "    self.alpha = alpha\n",
        "    self.r = None\n",
        "    self.coef_ = None\n",
        "    self.intercept_ = None\n",
        "    self.interpolated_coef_ = None\n",
        "    self.interpolated_intercept_ = None\n",
        "    self.class_weight = class_weight\n",
        "\n",
        "  def _log_probs(self, X, y):\n",
        "    p_sum = np.sum(X[y==1], axis=0) + self.alpha\n",
        "    n_sum = np.sum(X[y==0], axis=0) + self.alpha\n",
        "    p_tot = len(X[y==1]) + self.alpha\n",
        "    n_tot = len(X[y==0]) + self.alpha\n",
        "    p_ratio = p_sum/p_tot\n",
        "    n_ratio = n_sum/n_tot\n",
        "    self.r = np.log(p_ratio/n_ratio)\n",
        "    return self\n",
        "\n",
        "  def _binarize(self, X):\n",
        "    X[X>0] = 1\n",
        "    return X\n",
        "\n",
        "  def _interpolate(self, weights):\n",
        "    return (self.beta*weights) + (1-self.beta)*(np.mean(abs(weights)))\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    X_binarized = X.copy()\n",
        "    X_binarized = self._binarize(X_binarized)\n",
        "    self._log_probs(X_binarized, y)\n",
        "    del X_binarized\n",
        "    X_nb = X*self.r\n",
        "    svm = SVC(C=self.C, kernel=self.kernel, degree=self.degree, gamma=self.gamma, class_weight=self.class_weight)\n",
        "    svm.fit(X_nb, y)\n",
        "    self.coef_ = svm.coef_\n",
        "    self.intercept_ = svm.intercept_\n",
        "    self.interpolated_coef_ = self._interpolate(self.coef_)\n",
        "    self.interpolated_intercept_ = self._interpolate(self.intercept_)\n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    X_nb = X*self.r\n",
        "    preds = np.add(np.dot(X_nb, self.interpolated_coef_.transpose()), self.interpolated_intercept_)\n",
        "    preds[preds>0] = 1\n",
        "    preds[preds<=0] = 0\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODCNVjg-A4vI"
      },
      "source": [
        "### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_VwX4qt-cFc"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'alpha':list(np.arange(0.1,2.1,0.1)),\n",
        "    'C':[0.01,0.1,1,10,100],\n",
        "    'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'degree': list(np.arange(1,6,1)),\n",
        "    'gamma': ['scale', 'auto'],\n",
        "}\n",
        "nbsvm = NBSVMClassifier()\n",
        "clf = GridSearchCV(nbsvm, parameters, verbose=3, cv=2)\n",
        "clf.fit(df_vector, Class_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qe3riAi_KQv"
      },
      "outputs": [],
      "source": [
        "print('parameter terbaik : ',clf.best_params_)\n",
        "print('Akurasi parameter : ',clf.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quKPARR8A74z"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eX8eynjOWGDf",
        "outputId": "4777278b-d8e3-4246-e24c-4546cf526d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold ke =  1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.72      0.83       656\n",
            "           1       0.55      0.97      0.70       231\n",
            "\n",
            "    accuracy                           0.78       887\n",
            "   macro avg       0.77      0.84      0.76       887\n",
            "weighted avg       0.87      0.78      0.80       887\n",
            "\n",
            "Accuracy : 78.241 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.73      0.84       642\n",
            "           1       0.58      0.97      0.73       245\n",
            "\n",
            "    accuracy                           0.80       887\n",
            "   macro avg       0.78      0.85      0.78       887\n",
            "weighted avg       0.87      0.80      0.81       887\n",
            "\n",
            "Accuracy : 79.932 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.73      0.84       666\n",
            "           1       0.55      0.98      0.70       221\n",
            "\n",
            "    accuracy                           0.79       887\n",
            "   macro avg       0.77      0.86      0.77       887\n",
            "weighted avg       0.88      0.79      0.81       887\n",
            "\n",
            "Accuracy : 79.481 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.74      0.84       660\n",
            "           1       0.56      0.98      0.71       226\n",
            "\n",
            "    accuracy                           0.80       886\n",
            "   macro avg       0.77      0.86      0.78       886\n",
            "weighted avg       0.88      0.80      0.81       886\n",
            "\n",
            "Accuracy : 79.797 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.73      0.84       667\n",
            "           1       0.54      0.97      0.70       219\n",
            "\n",
            "    accuracy                           0.79       886\n",
            "   macro avg       0.77      0.85      0.77       886\n",
            "weighted avg       0.88      0.79      0.81       886\n",
            "\n",
            "Accuracy : 79.120 %\n",
            "--------------------------------------------------\n",
            "Rata-rata akurasi metode : 79.314 %\n"
          ]
        }
      ],
      "source": [
        "n_fold = 1\n",
        "akurasi = []\n",
        "for train_index, test_index in kf.split(df_vector):\n",
        "  print('Fold ke = ',n_fold)\n",
        "  x_train, x_test = df_vector.iloc[train_index], df_vector.iloc[test_index]\n",
        "  y_train, y_test = Class_encoder[train_index], Class_encoder[test_index]\n",
        "\n",
        "  NBSVM_model = NBSVMClassifier(**clf.best_params_)\n",
        "  NBSVM_model.fit(x_train,y_train)\n",
        "  NBSVM_pred = NBSVM_model.predict(x_test)\n",
        "\n",
        "  print(classification_report(y_test,NBSVM_pred))\n",
        "\n",
        "  unique, counts = np.unique((y_test == NBSVM_pred.reshape(NBSVM_pred.shape[0],)), return_counts=True)\n",
        "  acc = (counts[1]/np.sum(counts)) * 100\n",
        "  akurasi.append(acc)\n",
        "  n_fold += 1\n",
        "  print(f'Accuracy : {acc:.3f} %'.format(acc))\n",
        "  print('-'*50)\n",
        "\n",
        "print(f'Rata-rata akurasi metode : {np.mean(akurasi):.3f} %'.format(np.mean(akurasi)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DazS01Lbt5bK"
      },
      "source": [
        "## NB-MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x2Gn7HTht7dL"
      },
      "outputs": [],
      "source": [
        "class NBMLPClassifier(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, beta=0.5, alpha=1, activation='relu', solver='adam' ,learning_rate='constant',\n",
        "              class_weight='balanced'):\n",
        "    self.activation = activation\n",
        "    self.solver = solver\n",
        "    self.learning_rate = learning_rate\n",
        "    self.beta = beta\n",
        "    self.alpha = alpha\n",
        "    self.r = None\n",
        "    self.coef_ = None\n",
        "    self.intercept_ = None\n",
        "    self.interpolated_coef_ = None\n",
        "    self.interpolated_intercept_ = None\n",
        "\n",
        "  def _log_probs(self, X, y):\n",
        "    p_sum = np.sum(X[y==1], axis=0) + self.alpha\n",
        "    n_sum = np.sum(X[y==0], axis=0) + self.alpha\n",
        "    p_tot = len(X[y==1]) + self.alpha\n",
        "    n_tot = len(X[y==0]) + self.alpha\n",
        "    p_ratio = p_sum/p_tot\n",
        "    n_ratio = n_sum/n_tot\n",
        "    self.r = np.log(p_ratio/n_ratio)\n",
        "    return self\n",
        "\n",
        "  def _binarize(self, X):\n",
        "    X[X>0] = 1\n",
        "    return X\n",
        "\n",
        "  def _interpolate(self, weights):\n",
        "    return (self.beta*weights) + (1-self.beta)*(np.mean(abs(weights)))\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    X_binarized = X.copy()\n",
        "    X_binarized = self._binarize(X_binarized)\n",
        "    self._log_probs(X_binarized, y)\n",
        "    del X_binarized\n",
        "    X_nb = X*self.r\n",
        "    mlp = MLPClassifier(random_state=42, learning_rate=self.learning_rate, solver=self.solver,\n",
        "                            activation=self.activation)\n",
        "    mlp.fit(X_nb, y)\n",
        "    self.coef_ = mlp.coefs_[0].sum(axis=1)\n",
        "    self.intercept_ = mlp.intercepts_[1]\n",
        "    self.interpolated_coef_ = self._interpolate(self.coef_)\n",
        "    self.interpolated_intercept_ = self._interpolate(self.intercept_)\n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    X_nb = X*self.r\n",
        "    preds = np.add(np.dot(X_nb, self.interpolated_coef_.transpose()), self.interpolated_intercept_)\n",
        "    preds[preds>0] = 1\n",
        "    preds[preds<=0] = 0\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aJja86gA5Z2"
      },
      "source": [
        "### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrIX0s9x_PF_"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'alpha':list(np.arange(0.1,2.1,0.1)),\n",
        "    'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'solver':['lbfgs', 'sgd', 'adam'],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "}\n",
        "nbmlp = NBMLPClassifier()\n",
        "clf = GridSearchCV(nbmlp, parameters, verbose=3, cv=2)\n",
        "clf.fit(df_vector, Class_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGFn3xFU_PGA"
      },
      "outputs": [],
      "source": [
        "print('parameter terbaik : ',clf.best_params_)\n",
        "print('Akurasi parameter : ',clf.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IuM3hqhA8fW"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YGS4pllXWNH0",
        "outputId": "1f334954-4c73-4cd1-db7a-85567a9b63ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold ke =  1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82       656\n",
            "           1       0.51      0.71      0.60       231\n",
            "\n",
            "    accuracy                           0.75       887\n",
            "   macro avg       0.70      0.74      0.71       887\n",
            "weighted avg       0.79      0.75      0.76       887\n",
            "\n",
            "Accuracy : 74.859 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.77      0.82       642\n",
            "           1       0.55      0.74      0.63       245\n",
            "\n",
            "    accuracy                           0.76       887\n",
            "   macro avg       0.72      0.75      0.73       887\n",
            "weighted avg       0.79      0.76      0.77       887\n",
            "\n",
            "Accuracy : 76.212 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.75      0.81       666\n",
            "           1       0.49      0.73      0.59       221\n",
            "\n",
            "    accuracy                           0.74       887\n",
            "   macro avg       0.69      0.74      0.70       887\n",
            "weighted avg       0.79      0.74      0.76       887\n",
            "\n",
            "Accuracy : 74.295 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.78      0.83       660\n",
            "           1       0.53      0.70      0.60       226\n",
            "\n",
            "    accuracy                           0.76       886\n",
            "   macro avg       0.71      0.74      0.72       886\n",
            "weighted avg       0.79      0.76      0.77       886\n",
            "\n",
            "Accuracy : 76.298 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.77      0.82       667\n",
            "           1       0.49      0.68      0.57       219\n",
            "\n",
            "    accuracy                           0.75       886\n",
            "   macro avg       0.69      0.72      0.70       886\n",
            "weighted avg       0.78      0.75      0.76       886\n",
            "\n",
            "Accuracy : 74.718 %\n",
            "--------------------------------------------------\n",
            "Rata-rata akurasi metode : 75.276 %\n"
          ]
        }
      ],
      "source": [
        "n_fold = 1\n",
        "akurasi = []\n",
        "for train_index, test_index in kf.split(df_vector):\n",
        "  print('Fold ke = ',n_fold)\n",
        "  x_train, x_test = df_vector.iloc[train_index], df_vector.iloc[test_index]\n",
        "  y_train, y_test = Class_encoder[train_index], Class_encoder[test_index]\n",
        "\n",
        "  NBMLP_model = NBMLPClassifier(**clf.best_params_)\n",
        "  NBMLP_model.fit(x_train,y_train)\n",
        "  NBMLP_pred = NBMLP_model.predict(x_test)\n",
        "\n",
        "  print(classification_report(y_test,NBMLP_pred))\n",
        "\n",
        "  unique, counts = np.unique((y_test == NBMLP_pred.reshape(NBMLP_pred.shape[0],)), return_counts=True)\n",
        "  acc = (counts[1]/np.sum(counts)) * 100\n",
        "  akurasi.append(acc)\n",
        "  n_fold += 1\n",
        "  print(f'Accuracy : {acc:.3f} %'.format(acc))\n",
        "  print('-'*50)\n",
        "\n",
        "print(f'Rata-rata akurasi metode : {np.mean(akurasi):.3f} %'.format(np.mean(akurasi)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cczXt3Es8bY"
      },
      "source": [
        "## NB-SVM-MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyQ5PyAFCQ0m"
      },
      "outputs": [],
      "source": [
        "class NBMLPSVMClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, beta=0.5, alpha=1, activation='relu', solver='adam' ,learning_rate='constant',\n",
        "                 C=1.0, kernel='linear', degree=3 , gamma='auto',\n",
        "                 class_weight='balanced'):\n",
        "        self.C = C\n",
        "        self.kernel = kernel\n",
        "        self.degree = degree\n",
        "        self.gamma = gamma\n",
        "        self.activation = activation\n",
        "        self.solver = solver\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta = beta\n",
        "        self.alpha = alpha\n",
        "        self.r = None\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.interpolated_coef_ = None\n",
        "        self.interpolated_intercept_ = None\n",
        "        self.class_weight = class_weight\n",
        "\n",
        "    def _log_probs(self, X, y):\n",
        "        p_sum = np.sum(X[y==1], axis=0) + self.alpha\n",
        "        n_sum = np.sum(X[y==0], axis=0) + self.alpha\n",
        "        p_tot = len(X[y==1]) + self.alpha\n",
        "        n_tot = len(X[y==0]) + self.alpha\n",
        "        p_ratio = p_sum/p_tot\n",
        "        n_ratio = n_sum/n_tot\n",
        "        self.r = np.log(p_ratio/n_ratio)\n",
        "        return self\n",
        "\n",
        "    def _binarize(self, X):\n",
        "        X[X>0] = 1\n",
        "        return X\n",
        "\n",
        "    def _interpolate(self, weights):\n",
        "        return (self.beta*weights) + (1-self.beta)*(np.mean(abs(weights)))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_binarized = X.copy()\n",
        "        X_binarized = self._binarize(X_binarized)\n",
        "        self._log_probs(X_binarized, y)\n",
        "        del X_binarized\n",
        "        X_nb = X*self.r\n",
        "        svm = SVC(C=self.C, kernel=self.kernel, degree=self.degree, gamma=self.gamma, class_weight=self.class_weight)\n",
        "        svm.fit(X_nb, y)\n",
        "        mlp = MLPClassifier(random_state=42, learning_rate=self.learning_rate, solver=self.solver,\n",
        "                            activation=self.activation)\n",
        "        mlp.fit(X, y)\n",
        "        self.coef_ = np.add(svm.coef_ , mlp.coefs_[0].sum(axis=1))\n",
        "        self.intercept_ = np.add(svm.intercept_, mlp.intercepts_[1])\n",
        "        self.interpolated_coef_ = self._interpolate(self.coef_)\n",
        "        self.interpolated_intercept_ = self._interpolate(self.intercept_)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_nb = X*self.r\n",
        "        preds = np.add(np.dot(X_nb, self.interpolated_coef_.transpose()), self.interpolated_intercept_)\n",
        "        preds[preds>0] = 1\n",
        "        preds[preds<=0] = 0\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvO0sZ8iA6MN"
      },
      "source": [
        "### Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExArSaiMAHOy"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'alpha':list(np.arange(0.1,2.1,0.1)),\n",
        "    'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'solver':['lbfgs', 'sgd', 'adam'],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "    'C':[0.01,0.1,1,10,100],\n",
        "    'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'degree': list(np.arange(1,6,1)),\n",
        "    'gamma': ['scale', 'auto'],\n",
        "}\n",
        "nbsvmmlp = NBMLPSVMClassifier()\n",
        "clf = GridSearchCV(nbsvmmlp, parameters, verbose=3, cv=2)\n",
        "clf.fit(df_vector, Class_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHVU5UbDAHO0"
      },
      "outputs": [],
      "source": [
        "print('parameter terbaik : ',clf.best_params_)\n",
        "print('Akurasi parameter : ',clf.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dseTFZtiA9H6"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "smPfqr9iWShb",
        "outputId": "aa9f8af7-b907-4576-ce7b-71f41bfeaa21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold ke =  1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.75      0.84       656\n",
            "           1       0.56      0.90      0.69       231\n",
            "\n",
            "    accuracy                           0.79       887\n",
            "   macro avg       0.76      0.82      0.76       887\n",
            "weighted avg       0.85      0.79      0.80       887\n",
            "\n",
            "Accuracy : 78.805 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.77      0.85       642\n",
            "           1       0.60      0.90      0.72       245\n",
            "\n",
            "    accuracy                           0.80       887\n",
            "   macro avg       0.77      0.83      0.78       887\n",
            "weighted avg       0.85      0.80      0.81       887\n",
            "\n",
            "Accuracy : 80.383 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.74      0.84       666\n",
            "           1       0.55      0.95      0.70       221\n",
            "\n",
            "    accuracy                           0.79       887\n",
            "   macro avg       0.76      0.85      0.77       887\n",
            "weighted avg       0.87      0.79      0.81       887\n",
            "\n",
            "Accuracy : 79.369 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.75      0.84       660\n",
            "           1       0.55      0.90      0.68       226\n",
            "\n",
            "    accuracy                           0.78       886\n",
            "   macro avg       0.75      0.82      0.76       886\n",
            "weighted avg       0.85      0.78      0.80       886\n",
            "\n",
            "Accuracy : 78.442 %\n",
            "--------------------------------------------------\n",
            "Fold ke =  5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.75      0.84       667\n",
            "           1       0.54      0.89      0.67       219\n",
            "\n",
            "    accuracy                           0.78       886\n",
            "   macro avg       0.74      0.82      0.75       886\n",
            "weighted avg       0.85      0.78      0.80       886\n",
            "\n",
            "Accuracy : 78.217 %\n",
            "--------------------------------------------------\n",
            "Rata-rata akurasi metode : 79.043 %\n"
          ]
        }
      ],
      "source": [
        "n_fold = 1\n",
        "akurasi = []\n",
        "for train_index, test_index in kf.split(df_vector):\n",
        "  print('Fold ke = ',n_fold)\n",
        "  x_train, x_test = df_vector.iloc[train_index], df_vector.iloc[test_index]\n",
        "  y_train, y_test = Class_encoder[train_index], Class_encoder[test_index]\n",
        "\n",
        "  NBMLPSVM_model = NBMLPSVMClassifier(**clf.best_params_)\n",
        "  NBMLPSVM_model.fit(x_train,y_train)\n",
        "  NBMLPSVM_pred = NBMLPSVM_model.predict(x_test)\n",
        "\n",
        "  print(classification_report(y_test,NBMLPSVM_pred))\n",
        "\n",
        "  unique, counts = np.unique((y_test == NBMLPSVM_pred.reshape(NBMLPSVM_pred.shape[0],)), return_counts=True)\n",
        "  acc = (counts[1]/np.sum(counts)) * 100\n",
        "  akurasi.append(acc)\n",
        "  n_fold += 1\n",
        "  print(f'Accuracy : {acc:.3f} %'.format(acc))\n",
        "  print('-'*50)\n",
        "\n",
        "print(f'Rata-rata akurasi metode : {np.mean(akurasi):.3f} %'.format(np.mean(akurasi)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOJ9MmP9Rxsw118xxQTnlRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}